{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmic Complexity and Sorting Algorithms\n",
    "\n",
    "## Algorithmic Complexity\n",
    "\n",
    "An __algorithm__ is a self contained set of instructions that accomplishes a task - essentially a method. One of the main problems in Computer Science is determining the  efficiency of an algorithm. If we can develop efficient algorithms to solve common problems, we can greatly speed up common tasks in computing. This could have drastic consequences everything from software development and encryption to theoretical computer science. In fact - if you've heard of the P vs NP problem - the whole point of the P vs NP problem is to try to find fast algorithms for problems that we only know how to solve in a slow way. A solution to this problem has wide spreading implications, especially in cryptography / information security and a successful proof is worth at least $\\$1,000,000$. \n",
    "\n",
    "Algorithm analysis is pretty complicated and there are whole classes on the subject - here we'll cover the basics. In algorithm analysis we want to know, given the worst possible input, approximately how long does the algorithm take as a function of the input size. Another way to say this is: \"how does the running time of the algorithm grow with the size of the input?\".\n",
    "Consider this algorithm for calculating the sum of an array of integers. \n",
    "\n",
    "```Java\n",
    "public static int sum(int[] arr) {\n",
    "    int sum = 0;\n",
    "    for (int i = 0; i < arr.length; i++) {\n",
    "        sum += arr[i];\n",
    "    }\n",
    "    return sum;\n",
    "}\n",
    "```\n",
    "\n",
    "The first line takes $1$ step. The for loop iterates $N$ times where $N$ is the length of the array. Iterating takes $1$ step per iteration and the addition takes $1$ step. Returning also takes $1$ step. So we can say that this algorithm takes approximately $2N + 2$ steps. \n",
    "\n",
    "Being able to count the exact number of steps of an algorithm is great, but this calculation is tedious (and sometimes impossible) for more complicated algorithms. So generally we don't care about the exact number of steps, but rather the general form of the __fastest growing term__ in the function representing the number of steps of the algorithm. For example, in the sum algorithm, the function is $g(N) = 2N + 2$. The fastest growing term is $2N$ which increases linearly as $N$ increases. We can concisely say that this algorithm is $O(N)$. This means that the algorithm's growth is upper bounded by a linear function. \n",
    "\n",
    "This notation is also called Big-O notation. __If $f(N) \\in O(g(n))$ there exists some constant $c$ such that $f(N) \\leq cg(N) \\forall N \\geq N_0$ where $N_0$ is small. We would then say that $f(N)$ is $O(g(N))$__. If the number of steps taken by an algorithm is of the form $f(N)$ then we say that the algorithm's __time complexity__ is $O(g(N))$.\n",
    "\n",
    "![graphical depiction of big O](bigOGraph.png)\n",
    "\n",
    "In our sum example, $f(N) = 2N + 2 \\leq 3*(g(N) = N) \\forall N > 2$. So $f(N)$ is $O(N)$.\\\\\\\\\n",
    "When examining algorithms we care about which algorithms have the fastest time complexity. So it's helpful to know the relative efficiency of the common time complexities\n",
    "- $O(1)$ : Also called constant time - Fastest possible time complexity\n",
    "- $O(log_2(N))$ : Also called log time\n",
    "- $O(N)$ : Also called linear time\n",
    "- $O(N log_2(N))$\n",
    "- $O(N^2)$ : Also called quadratic time\n",
    "- $O(2^N)$ : Also called exponential time - This is the beginning of the \"slow algorithms\"\n",
    "- $O(N!)$\n",
    "\n",
    "![comparison of time complexities](bigO.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Algorithms\n",
    "\n",
    "The sorting problem is very simple to understand. Given a list of values, return a permutation of that list that is sorted. In this case we'll use ascending order, but you can use descending too. \n",
    "\n",
    "There are several solutions to this problem with varying time complexities. Here we will consider a few common sorting algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insertion Sort\n",
    "Insertion sort is a simple sorting algorithm that builds the final sorted array (or list) one item at a time. Insertion sort assumes that the front of the array is already sorted - it then selects the first unsorted element and inserts it in its proper position in the sorted section.\n",
    "\n",
    "![insertion sort](insertion.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 26, 37, 47, 61, 68, 83, 83, 91, 94]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def insertion_sort(arr):\n",
    "    n = len(arr)\n",
    "    for i in range(0, n):\n",
    "        j = i\n",
    "        while j > 0 and arr[j-1] > arr[j]:\n",
    "            # swap arr[j] and arr[j-1]\n",
    "            temp = arr[j]\n",
    "            arr[j] = arr[j-1]\n",
    "            arr[j-1] = temp\n",
    "            j = j - 1\n",
    "        i = i + 1\n",
    "    return arr\n",
    "\n",
    "insertion_sort([19, 37, 94, 61, 83, 83, 91, 47, 26, 68])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The worst case for this algorithm is that the list is initially in reverse order. If we trace through the pseudocode in the worst case we see that insertion sort is $O(N^2)$ where $N = len(A)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection Sort\n",
    "\n",
    "Selection sort is very similar to selection sort. It assumes the front of the array is already sorted - it then selects the first unsorted element and swaps it with the smallest element in the unsorted part of the array.\n",
    "\n",
    "![selection sort](selection.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 26, 37, 47, 61, 68, 83, 83, 91, 94]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def selection_sort(arr):\n",
    "    for j in range(len(arr)):\n",
    "        smallest = j\n",
    "        for i in range(j + 1, len(arr)):\n",
    "            if arr[i] < arr[smallest]:\n",
    "                smallest = i\n",
    "        temp = arr[j]\n",
    "        arr[j] = arr[smallest]\n",
    "        arr[smallest] = temp\n",
    "    return arr\n",
    "\n",
    "selection_sort([19, 37, 94, 61, 83, 83, 91, 47, 26, 68])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The worst case for this algorithm is that the list is initially in reverse order. If we trace through the pseudocode in the worst case we see that insertion sort is $O(N^2)$ where $N = len(A)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bubble Sort\n",
    "\n",
    "Bubble sort is a sorting algorithm that takes a slightly different approach than insertion and selection sort. It repeatedly steps through the list to be sorted, compares each pair of adjacent items and swaps them if they are in the wrong order. The pass through the list is repeated until no swaps are needed, which indicates that the list is sorted.\n",
    "\n",
    "![bubble sort](bubble.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 26, 37, 47, 61, 68, 83, 83, 91, 94]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bubble_sort(arr):\n",
    "    n = length(arr)\n",
    "    swapped = False\n",
    "    while not swapped:\n",
    "        swapped = False\n",
    "        for i in range(1, len(arr)):\n",
    "            if arr[i-1] > arr[i]:\n",
    "                temp = arr[i-1]\n",
    "                arr[i-1] = arr[i]\n",
    "                arr[i] = temp\n",
    "                swapped = True\n",
    "    return arr\n",
    "\n",
    "selection_sort([19, 37, 94, 61, 83, 83, 91, 47, 26, 68])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The worst case for this algorithm is that the list is initially in reverse order. If we trace through the pseudocode in the worst case we see that insertion sort is $O(N^2)$ where $N = len(A)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Sort\n",
    "\n",
    "So far our sorting algorithms have been sorting in the most naive way - that is, we're sorting in a conceptually easy, but inefficient way. But since sorting is a pretty important procedure, we want to be able to sort faster than $O(N^2)$. \n",
    "\n",
    "Merge Sort is a sorting algorithm that takes advantage of recursion to efficiently sort an array. Merge sort splits the array in half and recursively sorts each unsorted half of the array. The base case is when the array is of length 1 where the array itself is returned. \n",
    "\n",
    "![merge sort](merge.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 26, 37, 47, 61, 68, 83, 83, 91, 94]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge(arr_a, arr_b):\n",
    "    '''\n",
    "     Merges two sorted arrays into one large sort\n",
    "    '''\n",
    "    N = max(len(arr_a), len(arr_b))\n",
    "    ret = list()\n",
    "    a, b = 0, 0\n",
    "    while a < len(arr_a) and b < len(arr_b):\n",
    "        if arr_a[a] <= arr_b[b]:\n",
    "            ret.append(arr_a[a])\n",
    "            a+=1\n",
    "        else:\n",
    "            ret.append(arr_b[b])\n",
    "            b+=1\n",
    "    while a < len(arr_a):\n",
    "        ret.append(arr_a[a])\n",
    "        a+=1\n",
    "    while b < len(arr_b):\n",
    "        ret.append(arr_b[b])\n",
    "        b+=1\n",
    "    return ret\n",
    "\n",
    "def merge_sort(arr):\n",
    "    if len(arr) == 1:\n",
    "        return arr\n",
    "    mid = len(arr) // 2\n",
    "    left = merge_sort(arr[:mid])\n",
    "    right = merge_sort(arr[mid:])\n",
    "    return merge(left, right)\n",
    "\n",
    "merge_sort([19, 37, 94, 61, 83, 83, 91, 47, 26, 68])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an algorithms class you prove that the time complexity of merge sort is $O(N log_2(N))$. This is significantly better than the previous algorithms which are $O(N^2)$. We can also reason this out ourselves. By inspecting the pseudocode for merge we see that it is $O(N)$. Then each level of merge sort splits the array in half (divides N by 2) and calls merge. There are $log_2(N)$ levels of merge sort since it takes that many divisions to get an array of length $1$ and each level calls an $O(N)$ operations. Therefore the time complexity is $O(N log_2(N))$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Sorting Algorithms\n",
    "\n",
    "It can be proven that the fastest general purpose sorting algorithm is $O(N log_2(N))$. However, if we know some basic properties of the data (ie if we can assume that they're small integers) we can reduce the time complexity even further. We don't go over these algorithms in this class, but if you're interested some more advanced sorting algorithms include:\n",
    "- Quicksort : A more complicated general purpose sorting algorithm. Used as an alternative to merge sort because it requires less extra space. \n",
    "- Counting Sort : A sorting algorithm that can efficiently sort arrays of relatively small integers. \n",
    "- Radix Sort : A sorting algorithm that can efficiently sort data with mixed types (ie sorting alphanumeric sequences). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
